{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Key-Value Bottleneck: A Simple Learning Setting Motivating the Method\n",
    "\n",
    "We consider a 2D input feature classification problem for 8\n",
    "classes, where the training data is not i.i.d. but changes over\n",
    "four stages. In each stage, we sample 100\n",
    "examples of two classes for 1000 training steps, using gradient descent to update the weights, then move on to two new\n",
    "classes for the next 1000 steps. The input features of each\n",
    "class follow spatially separated normal distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8\n",
    "INPUT_DIM = 2\n",
    "OUTPUT_DIM = 8\n",
    "SAMPLES_PER_CLASS = 100\n",
    "\n",
    "NUM_EPOCHS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Toy Synthetic Dataset.csv\")\n",
    "df.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# df[['Feature_1', 'Feature_2']] = scaler.fit_transform(df[['Feature_1', 'Feature_2']])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(NUM_CLASSES):\n",
    "    plt.scatter(df[df[\"Labels\"] == i][\"Feature_1\"], df[df[\"Labels\"] == i][\"Feature_2\"], \n",
    "                label=f'Class {i}', s=10)\n",
    "plt.legend()\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('2D Features with eight classes')\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(df.drop(columns=\"Labels\").to_numpy(), dtype=float)\n",
    "y = torch.tensor(df[\"Labels\"].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Function to display the decision boundaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_datapoints_and_decision_boundary(model, X, y, lim=15, resolution=0.01, h=0.1):\n",
    "    \n",
    "    model.eval()    \n",
    "    xx, yy = np.meshgrid(np.arange(-lim, lim, h), np.arange(-lim, lim, h))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    input = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    Z = model(torch.tensor(input).float()).detach()\n",
    "    \n",
    "    Z = torch.argmax(Z, dim=1)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    ax.contourf(xx, yy, Z.numpy(), cmap=\"viridis\", alpha=0.5)\n",
    "    \n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=\"jet\", s=10)\n",
    "    ax.set_xlim(-lim, lim)\n",
    "    ax.set_ylim(-lim, lim)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_incrementally(num_epochs, X, y, model, loss_criterion, optimizer, scheduler=None):\n",
    "    \n",
    "    delta = int(X.shape[0] / 2)\n",
    "    losses = []\n",
    "    for i in range(int(NUM_CLASSES/2)):\n",
    "        X_train = torch.vstack([X[i * SAMPLES_PER_CLASS : (i + 1) * SAMPLES_PER_CLASS], \n",
    "                                X[i * SAMPLES_PER_CLASS + delta: (i + 1) * SAMPLES_PER_CLASS + delta]]).float()\n",
    "        \n",
    "        y_train = torch.vstack([y[i * SAMPLES_PER_CLASS : (i + 1) * SAMPLES_PER_CLASS], \n",
    "                                y[i * SAMPLES_PER_CLASS + delta: (i + 1) * SAMPLES_PER_CLASS + delta]])\n",
    "        y_train = y_train.reshape(2 * SAMPLES_PER_CLASS)\n",
    "        print(f\"Classes being trained on are: {y_train.unique()}\")\n",
    "        \n",
    "        dataset = TensorDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, labels in train_loader:\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward() \n",
    "                optimizer.step()  \n",
    "            \n",
    "            if epoch % int(NUM_EPOCHS/10) == 0:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "        print(f\"Training period { i + 1 } completed\")\n",
    "        \n",
    "        plt.plot(losses)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Training Loss\")\n",
    "\n",
    "        plot_datapoints_and_decision_boundary(model, X_train.detach().numpy(), y_train.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_to_zero(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.zeros_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias) \n",
    "            \n",
    "def init_weights_kaiming(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbe(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.linear_layer(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_probe = LinearProbe(INPUT_DIM, NUM_CLASSES)\n",
    "optimizer = optim.SGD(linear_probe.parameters(), lr=0.05)\n",
    "\n",
    "linear_probe.apply(init_weights_to_zero)\n",
    "train_incrementally(NUM_EPOCHS, X, y, linear_probe, loss_criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datapoints_and_decision_boundary(linear_probe, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveMLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.hidden_layer(x)\n",
    "        activations = self.relu(h)\n",
    "        z = self.output_layer(activations)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveMLP32 = NaiveMLP(INPUT_DIM, 32, NUM_CLASSES)\n",
    "optimizer = optim.SGD(naiveMLP32.parameters(), lr=0.01)\n",
    "\n",
    "naiveMLP32.apply(init_weights_kaiming)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "train_incrementally(NUM_EPOCHS, X, y, naiveMLP32, loss_criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datapoints_and_decision_boundary(naiveMLP32, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiscreteKeyValueBottleneck import DiscreteKeyValueBottleneck\n",
    "\n",
    "dkvb = DiscreteKeyValueBottleneck(encoder=None,\n",
    "                                  num_codebooks=1,\n",
    "                                  embed_dim=2,\n",
    "                                  value_dim=8,\n",
    "                                  keys_per_codebook=400,\n",
    "                                  naive=True,\n",
    "                                  requires_random_projection=True)\n",
    "\n",
    "optimizer = optim.SGD(dkvb.parameters(), lr=0.001)\n",
    "\n",
    "dkvb.apply(init_weights_kaiming)\n",
    "train_incrementally(NUM_EPOCHS, X, y, dkvb, loss_criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datapoints_and_decision_boundary(dkvb, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
